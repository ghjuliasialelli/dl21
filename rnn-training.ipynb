{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "departmental-transsexual",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from utils.model_operations import *\n",
    "from utils.image_operations import *\n",
    "\n",
    "directory_path = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "established-taxation",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def loadModelWeights(setName, percentage=1):\n",
    "    \"\"\"\n",
    "    setname: either \"train\" or \"test\"\n",
    "    \n",
    "    returns dataframe with the weights of all models by layers\n",
    "    \"\"\"\n",
    "    bias = ['0.02', '0.03', '0.04', '0.05']\n",
    "    df = pd.DataFrame()\n",
    "    modelId = 0\n",
    "    for b in bias:\n",
    "        if setName == \"train\":\n",
    "            model_data = ModelDataset(bias=b, data_directory=directory_path+'/data/DigitWdb/train')\n",
    "        elif setName == \"test\":\n",
    "            model_data = ModelDataset(bias=b, data_directory=directory_path+'/data/DigitWdb/test')\n",
    "        else:\n",
    "            raise \"set name must either be train or test\"\n",
    "            \n",
    "        for modelNumber in tqdm(range(len(model_data)//percentage), desc=\"loading model weights with bias \"+b):\n",
    "            model = model_data[modelNumber]\n",
    "            layerNumber = 0\n",
    "            for layer in model.layers:\n",
    "                if len(layer.get_weights()) != 0:\n",
    "                    # weights\n",
    "                    weights = layer.get_weights()[0]\n",
    "                    # biases\n",
    "                    biases = layer.get_weights()[1]\n",
    "\n",
    "                    df = df.append({'modelId':modelId,'weights':np.ravel(weights),'biases':np.ravel(biases),'layer':layerNumber, 'bias':b}, ignore_index=True)\n",
    "                    layerNumber = layerNumber + 1\n",
    "            modelId += 1       \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e437e4fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading model weights with bias 0.02:   0%|          | 0/2000 [00:00<?, ?it/s]2021-12-21 10:57:19.756498: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "loading model weights with bias 0.02: 100%|██████████| 2000/2000 [05:17<00:00,  6.30it/s]\n",
      "loading model weights with bias 0.03: 100%|██████████| 2000/2000 [04:07<00:00,  8.09it/s]\n",
      "loading model weights with bias 0.04: 100%|██████████| 2000/2000 [04:31<00:00,  7.36it/s]\n",
      "loading model weights with bias 0.05: 100%|██████████| 2000/2000 [05:42<00:00,  5.84it/s]\n",
      "loading model weights with bias 0.02: 100%|██████████| 500/500 [01:25<00:00,  5.82it/s]\n",
      "loading model weights with bias 0.03: 100%|██████████| 500/500 [01:21<00:00,  6.17it/s]\n",
      "loading model weights with bias 0.04: 100%|██████████| 500/500 [01:31<00:00,  5.47it/s]\n",
      "loading model weights with bias 0.05: 100%|██████████| 500/500 [01:30<00:00,  5.53it/s]\n"
     ]
    }
   ],
   "source": [
    "trainModelWeights = loadModelWeights(\"train\", percentage = 1)\n",
    "testModelWeights = loadModelWeights(\"test\",  percentage = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "66ef760d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>modelId</th>\n",
       "      <th>weights</th>\n",
       "      <th>biases</th>\n",
       "      <th>layer</th>\n",
       "      <th>bias</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>[-0.018486138, -0.03354981, -0.16535422, -0.06...</td>\n",
       "      <td>[-0.24564764, -0.081536554, -0.01958792, -0.11...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>[-0.26035, -0.031969644, 0.02034611, 0.0241116...</td>\n",
       "      <td>[-0.08751261, 0.14474091, -0.26124775, -0.2221...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>[-0.045246184, -0.022445709, -0.17450637, -0.0...</td>\n",
       "      <td>[0.18726698, -0.055855844, 0.10226409, -0.1979...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>[0.14023237, -0.0014608316, 0.17644557, 0.1682...</td>\n",
       "      <td>[-0.11819455, 0.109577455, -0.034734905, 0.126...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>[-0.25628987, 0.017059373, -0.14892107, 0.1850...</td>\n",
       "      <td>[0.04371279, 0.1927553, -0.0704351, 0.02792670...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39995</th>\n",
       "      <td>7999.0</td>\n",
       "      <td>[-0.057432093, 0.012581817, 0.11414536, 0.0184...</td>\n",
       "      <td>[-0.0671344, -0.0277758, -0.0146967145, 0.0630...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39996</th>\n",
       "      <td>7999.0</td>\n",
       "      <td>[-0.107280254, -0.09203529, -0.07334799, -0.10...</td>\n",
       "      <td>[-0.03721022, 0.040936325, -0.030625928, 0.002...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39997</th>\n",
       "      <td>7999.0</td>\n",
       "      <td>[0.011979358, -0.034554373, -0.051180247, -0.0...</td>\n",
       "      <td>[0.010443132, -0.18427786, -0.066259846, -0.03...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39998</th>\n",
       "      <td>7999.0</td>\n",
       "      <td>[-2.1241395, 0.58485734, -2.2942114, 0.4497387...</td>\n",
       "      <td>[3.359927, 1.6769673, 2.8587103, 2.1773515, 2....</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39999</th>\n",
       "      <td>7999.0</td>\n",
       "      <td>[-0.038149532, -0.024797479, 0.02632919, 0.175...</td>\n",
       "      <td>[-0.100846305, -0.051194046, 0.045621414, -0.0...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>40000 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       modelId                                            weights  \\\n",
       "0          0.0  [-0.018486138, -0.03354981, -0.16535422, -0.06...   \n",
       "1          0.0  [-0.26035, -0.031969644, 0.02034611, 0.0241116...   \n",
       "2          0.0  [-0.045246184, -0.022445709, -0.17450637, -0.0...   \n",
       "3          0.0  [0.14023237, -0.0014608316, 0.17644557, 0.1682...   \n",
       "4          0.0  [-0.25628987, 0.017059373, -0.14892107, 0.1850...   \n",
       "...        ...                                                ...   \n",
       "39995   7999.0  [-0.057432093, 0.012581817, 0.11414536, 0.0184...   \n",
       "39996   7999.0  [-0.107280254, -0.09203529, -0.07334799, -0.10...   \n",
       "39997   7999.0  [0.011979358, -0.034554373, -0.051180247, -0.0...   \n",
       "39998   7999.0  [-2.1241395, 0.58485734, -2.2942114, 0.4497387...   \n",
       "39999   7999.0  [-0.038149532, -0.024797479, 0.02632919, 0.175...   \n",
       "\n",
       "                                                  biases  layer  bias  \n",
       "0      [-0.24564764, -0.081536554, -0.01958792, -0.11...    0.0  0.02  \n",
       "1      [-0.08751261, 0.14474091, -0.26124775, -0.2221...    1.0  0.02  \n",
       "2      [0.18726698, -0.055855844, 0.10226409, -0.1979...    2.0  0.02  \n",
       "3      [-0.11819455, 0.109577455, -0.034734905, 0.126...    3.0  0.02  \n",
       "4      [0.04371279, 0.1927553, -0.0704351, 0.02792670...    4.0  0.02  \n",
       "...                                                  ...    ...   ...  \n",
       "39995  [-0.0671344, -0.0277758, -0.0146967145, 0.0630...    0.0  0.05  \n",
       "39996  [-0.03721022, 0.040936325, -0.030625928, 0.002...    1.0  0.05  \n",
       "39997  [0.010443132, -0.18427786, -0.066259846, -0.03...    2.0  0.05  \n",
       "39998  [3.359927, 1.6769673, 2.8587103, 2.1773515, 2....    3.0  0.05  \n",
       "39999  [-0.100846305, -0.051194046, 0.045621414, -0.0...    4.0  0.05  \n",
       "\n",
       "[40000 rows x 5 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainModelWeights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "41eea9ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "82c14c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply PCA \n",
    "\n",
    "def apply_PCA(trainModelWeights, testModelWeights, components=1000):\n",
    "\n",
    "    pca_train_weights = []\n",
    "    pca_test_weights = []\n",
    "\n",
    "    for layer in range(5) :\n",
    "        \n",
    "        X_train = [x[0] for x in trainModelWeights[trainModelWeights['layer'] == 0][['weights']].values]\n",
    "        X_test = [x[0] for x in testModelWeights[testModelWeights['layer'] == 0][['weights']].values]\n",
    "        \n",
    "        pca_train, pca_test = PCA(n_components = components), PCA(n_components = components)\n",
    "        pca_train_weights.append(pca_train.fit_transform(X_train))\n",
    "        pca_test_weights.append(pca_test.fit_transform(X_test))      \n",
    "\n",
    "    return pca_train_weights, pca_test_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d379bc58",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_train_weights, pca_test_weights = apply_PCA(trainModelWeights, testModelWeights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "69bf49a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_PCA_ModelWeights(ModelWeights, pca_model_weights) :\n",
    "    PCA_ModelWeights = ModelWeights.copy()\n",
    "    ordered_pca_weights = []\n",
    "\n",
    "    for l0,l1,l2,l3,l4 in zip(pca_model_weights[0], pca_model_weights[1],pca_model_weights[2],pca_model_weights[3],pca_model_weights[4]) :\n",
    "        ordered_pca_weights.append(l0)\n",
    "        ordered_pca_weights.append(l1)\n",
    "        ordered_pca_weights.append(l2)\n",
    "        ordered_pca_weights.append(l3)\n",
    "        ordered_pca_weights.append(l4)\n",
    "\n",
    "    PCA_ModelWeights = PCA_ModelWeights.assign(pca_weights=ordered_pca_weights)\n",
    "\n",
    "    return PCA_ModelWeights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1bc93ee5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>modelId</th>\n",
       "      <th>weights</th>\n",
       "      <th>biases</th>\n",
       "      <th>layer</th>\n",
       "      <th>bias</th>\n",
       "      <th>pca_weights</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>[-0.018486138, -0.03354981, -0.16535422, -0.06...</td>\n",
       "      <td>[-0.24564764, -0.081536554, -0.01958792, -0.11...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.02</td>\n",
       "      <td>[0.27218338595085156, -0.23092936699232702, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>[-0.26035, -0.031969644, 0.02034611, 0.0241116...</td>\n",
       "      <td>[-0.08751261, 0.14474091, -0.26124775, -0.2221...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.02</td>\n",
       "      <td>[0.2721835207775092, -0.23092942237932645, 0.4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>[-0.045246184, -0.022445709, -0.17450637, -0.0...</td>\n",
       "      <td>[0.18726698, -0.055855844, 0.10226409, -0.1979...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.02</td>\n",
       "      <td>[0.27218353164205855, -0.2309295389616671, 0.4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>[0.14023237, -0.0014608316, 0.17644557, 0.1682...</td>\n",
       "      <td>[-0.11819455, 0.109577455, -0.034734905, 0.126...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.02</td>\n",
       "      <td>[0.27218357880894917, -0.23092942462262803, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>[-0.25628987, 0.017059373, -0.14892107, 0.1850...</td>\n",
       "      <td>[0.04371279, 0.1927553, -0.0704351, 0.02792670...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.02</td>\n",
       "      <td>[0.2721834439108311, -0.2309294317667347, 0.42...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39995</th>\n",
       "      <td>7999.0</td>\n",
       "      <td>[-0.057432093, 0.012581817, 0.11414536, 0.0184...</td>\n",
       "      <td>[-0.0671344, -0.0277758, -0.0146967145, 0.0630...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>[-0.35919388344761505, -0.19275044802463717, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39996</th>\n",
       "      <td>7999.0</td>\n",
       "      <td>[-0.107280254, -0.09203529, -0.07334799, -0.10...</td>\n",
       "      <td>[-0.03721022, 0.040936325, -0.030625928, 0.002...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>[-0.3591939800873321, -0.19275039739512664, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39997</th>\n",
       "      <td>7999.0</td>\n",
       "      <td>[0.011979358, -0.034554373, -0.051180247, -0.0...</td>\n",
       "      <td>[0.010443132, -0.18427786, -0.066259846, -0.03...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>[-0.35919376156186106, -0.19275017446237078, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39998</th>\n",
       "      <td>7999.0</td>\n",
       "      <td>[-2.1241395, 0.58485734, -2.2942114, 0.4497387...</td>\n",
       "      <td>[3.359927, 1.6769673, 2.8587103, 2.1773515, 2....</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>[-0.3591938465531692, -0.19275023074961442, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39999</th>\n",
       "      <td>7999.0</td>\n",
       "      <td>[-0.038149532, -0.024797479, 0.02632919, 0.175...</td>\n",
       "      <td>[-0.100846305, -0.051194046, 0.045621414, -0.0...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>[-0.3591937559723671, -0.1927503193369775, -0....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>40000 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       modelId                                            weights  \\\n",
       "0          0.0  [-0.018486138, -0.03354981, -0.16535422, -0.06...   \n",
       "1          0.0  [-0.26035, -0.031969644, 0.02034611, 0.0241116...   \n",
       "2          0.0  [-0.045246184, -0.022445709, -0.17450637, -0.0...   \n",
       "3          0.0  [0.14023237, -0.0014608316, 0.17644557, 0.1682...   \n",
       "4          0.0  [-0.25628987, 0.017059373, -0.14892107, 0.1850...   \n",
       "...        ...                                                ...   \n",
       "39995   7999.0  [-0.057432093, 0.012581817, 0.11414536, 0.0184...   \n",
       "39996   7999.0  [-0.107280254, -0.09203529, -0.07334799, -0.10...   \n",
       "39997   7999.0  [0.011979358, -0.034554373, -0.051180247, -0.0...   \n",
       "39998   7999.0  [-2.1241395, 0.58485734, -2.2942114, 0.4497387...   \n",
       "39999   7999.0  [-0.038149532, -0.024797479, 0.02632919, 0.175...   \n",
       "\n",
       "                                                  biases  layer  bias  \\\n",
       "0      [-0.24564764, -0.081536554, -0.01958792, -0.11...    0.0  0.02   \n",
       "1      [-0.08751261, 0.14474091, -0.26124775, -0.2221...    1.0  0.02   \n",
       "2      [0.18726698, -0.055855844, 0.10226409, -0.1979...    2.0  0.02   \n",
       "3      [-0.11819455, 0.109577455, -0.034734905, 0.126...    3.0  0.02   \n",
       "4      [0.04371279, 0.1927553, -0.0704351, 0.02792670...    4.0  0.02   \n",
       "...                                                  ...    ...   ...   \n",
       "39995  [-0.0671344, -0.0277758, -0.0146967145, 0.0630...    0.0  0.05   \n",
       "39996  [-0.03721022, 0.040936325, -0.030625928, 0.002...    1.0  0.05   \n",
       "39997  [0.010443132, -0.18427786, -0.066259846, -0.03...    2.0  0.05   \n",
       "39998  [3.359927, 1.6769673, 2.8587103, 2.1773515, 2....    3.0  0.05   \n",
       "39999  [-0.100846305, -0.051194046, 0.045621414, -0.0...    4.0  0.05   \n",
       "\n",
       "                                             pca_weights  \n",
       "0      [0.27218338595085156, -0.23092936699232702, 0....  \n",
       "1      [0.2721835207775092, -0.23092942237932645, 0.4...  \n",
       "2      [0.27218353164205855, -0.2309295389616671, 0.4...  \n",
       "3      [0.27218357880894917, -0.23092942462262803, 0....  \n",
       "4      [0.2721834439108311, -0.2309294317667347, 0.42...  \n",
       "...                                                  ...  \n",
       "39995  [-0.35919388344761505, -0.19275044802463717, -...  \n",
       "39996  [-0.3591939800873321, -0.19275039739512664, -0...  \n",
       "39997  [-0.35919376156186106, -0.19275017446237078, -...  \n",
       "39998  [-0.3591938465531692, -0.19275023074961442, -0...  \n",
       "39999  [-0.3591937559723671, -0.1927503193369775, -0....  \n",
       "\n",
       "[40000 rows x 6 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PCA_trainModelWeights = get_PCA_ModelWeights(trainModelWeights, pca_train_weights)\n",
    "PCA_trainModelWeights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "575525cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>modelId</th>\n",
       "      <th>weights</th>\n",
       "      <th>biases</th>\n",
       "      <th>layer</th>\n",
       "      <th>bias</th>\n",
       "      <th>pca_weights</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>[-0.1984677, 0.10607128, 0.02757767, 0.0406214...</td>\n",
       "      <td>[-0.00082488754, -0.16404912, -0.16673991, -0....</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.02</td>\n",
       "      <td>[-0.23674860326346703, 0.07364349198241137, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>[0.06169182, 0.018116117, -0.078252785, -0.048...</td>\n",
       "      <td>[0.06270617, -0.033355515, -0.11744473, -0.136...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.02</td>\n",
       "      <td>[-0.2367486075147536, 0.07364348784942609, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>[0.09816912, 0.0027613225, -0.063564785, -0.11...</td>\n",
       "      <td>[-0.1339934, -0.12545621, -0.012984574, -0.121...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.02</td>\n",
       "      <td>[-0.23674859934792292, 0.07364349615562643, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>[0.29807323, -0.0807626, 0.045929182, 0.105066...</td>\n",
       "      <td>[0.10184695, 0.0049716868, 0.12874022, -0.0309...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.02</td>\n",
       "      <td>[-0.2367485972881196, 0.07364349192679322, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>[0.12900397, -0.062988736, 0.09713919, 0.02682...</td>\n",
       "      <td>[0.089443825, 0.16108993, -0.08055692, -0.0364...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.02</td>\n",
       "      <td>[-0.23674859483867847, 0.07364349996698968, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>1999.0</td>\n",
       "      <td>[-0.0016367873, 0.14418039, 0.005059285, -0.03...</td>\n",
       "      <td>[0.082041904, 0.023735803, -0.07432411, -0.174...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>[-0.3308803270132464, 0.602044477663766, 0.110...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>1999.0</td>\n",
       "      <td>[0.041652713, 0.10205761, -0.04620276, -0.0346...</td>\n",
       "      <td>[-0.07159305, 0.053167004, 0.0056193713, -0.14...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>[-0.330880323035721, 0.6020444815122841, 0.110...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>1999.0</td>\n",
       "      <td>[0.21854231, 0.004612843, -0.030746, 0.0026039...</td>\n",
       "      <td>[-0.13545194, 0.031433977, 0.055850044, 0.0190...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>[-0.33088032561464514, 0.6020444811758117, 0.1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>1999.0</td>\n",
       "      <td>[0.95756173, -0.75992316, -1.1382076, 0.616622...</td>\n",
       "      <td>[2.1560273, 0.8526798, 2.0636926, -0.86297965,...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>[-0.3308803539595303, 0.60204446760873, 0.1109...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>1999.0</td>\n",
       "      <td>[-0.26666394, 0.104369916, 0.0029272356, -0.15...</td>\n",
       "      <td>[-0.028910149, -0.073782325, -0.055152167, -0....</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>[-0.3308803469141923, 0.6020444771362709, 0.11...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      modelId                                            weights  \\\n",
       "0         0.0  [-0.1984677, 0.10607128, 0.02757767, 0.0406214...   \n",
       "1         0.0  [0.06169182, 0.018116117, -0.078252785, -0.048...   \n",
       "2         0.0  [0.09816912, 0.0027613225, -0.063564785, -0.11...   \n",
       "3         0.0  [0.29807323, -0.0807626, 0.045929182, 0.105066...   \n",
       "4         0.0  [0.12900397, -0.062988736, 0.09713919, 0.02682...   \n",
       "...       ...                                                ...   \n",
       "9995   1999.0  [-0.0016367873, 0.14418039, 0.005059285, -0.03...   \n",
       "9996   1999.0  [0.041652713, 0.10205761, -0.04620276, -0.0346...   \n",
       "9997   1999.0  [0.21854231, 0.004612843, -0.030746, 0.0026039...   \n",
       "9998   1999.0  [0.95756173, -0.75992316, -1.1382076, 0.616622...   \n",
       "9999   1999.0  [-0.26666394, 0.104369916, 0.0029272356, -0.15...   \n",
       "\n",
       "                                                 biases  layer  bias  \\\n",
       "0     [-0.00082488754, -0.16404912, -0.16673991, -0....    0.0  0.02   \n",
       "1     [0.06270617, -0.033355515, -0.11744473, -0.136...    1.0  0.02   \n",
       "2     [-0.1339934, -0.12545621, -0.012984574, -0.121...    2.0  0.02   \n",
       "3     [0.10184695, 0.0049716868, 0.12874022, -0.0309...    3.0  0.02   \n",
       "4     [0.089443825, 0.16108993, -0.08055692, -0.0364...    4.0  0.02   \n",
       "...                                                 ...    ...   ...   \n",
       "9995  [0.082041904, 0.023735803, -0.07432411, -0.174...    0.0  0.05   \n",
       "9996  [-0.07159305, 0.053167004, 0.0056193713, -0.14...    1.0  0.05   \n",
       "9997  [-0.13545194, 0.031433977, 0.055850044, 0.0190...    2.0  0.05   \n",
       "9998  [2.1560273, 0.8526798, 2.0636926, -0.86297965,...    3.0  0.05   \n",
       "9999  [-0.028910149, -0.073782325, -0.055152167, -0....    4.0  0.05   \n",
       "\n",
       "                                            pca_weights  \n",
       "0     [-0.23674860326346703, 0.07364349198241137, -0...  \n",
       "1     [-0.2367486075147536, 0.07364348784942609, -0....  \n",
       "2     [-0.23674859934792292, 0.07364349615562643, -0...  \n",
       "3     [-0.2367485972881196, 0.07364349192679322, -0....  \n",
       "4     [-0.23674859483867847, 0.07364349996698968, -0...  \n",
       "...                                                 ...  \n",
       "9995  [-0.3308803270132464, 0.602044477663766, 0.110...  \n",
       "9996  [-0.330880323035721, 0.6020444815122841, 0.110...  \n",
       "9997  [-0.33088032561464514, 0.6020444811758117, 0.1...  \n",
       "9998  [-0.3308803539595303, 0.60204446760873, 0.1109...  \n",
       "9999  [-0.3308803469141923, 0.6020444771362709, 0.11...  \n",
       "\n",
       "[10000 rows x 6 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PCA_testModelWeights = get_PCA_ModelWeights(testModelWeights, pca_test_weights)\n",
    "PCA_testModelWeights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c6416b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_iterator(ids, ModelWeights, feature, label):\n",
    "\n",
    "    dataset = []\n",
    "    labels = []\n",
    "\n",
    "    for modelid in ids : \n",
    "\n",
    "        X = ModelWeights[ModelWeights['modelId'] == modelid][[feature]].values[:,0]\n",
    "        if label == 'one' :\n",
    "            y = float(ModelWeights[ModelWeights['modelId'] == modelid][['bias']].values[:,0][0])\n",
    "        else : \n",
    "            y = [float(b) for b in ModelWeights[ModelWeights['modelId'] == modelid][['bias']].values[:,0]]\n",
    "\n",
    "        layers = []\n",
    "        for layer in X : \n",
    "            # nothing because testing PCA \n",
    "            # layer = np.random.choice(layer, size = 1000, replace = False) # random sampling\n",
    "            # layer = np.pad(layer, pad_width=(0, 27648 - len(layer)))    # padding for Conv1d layer\n",
    "            layers.append(layer)\n",
    "        \n",
    "        dataset.append(layers)\n",
    "        labels.append(y)\n",
    "    \n",
    "    return dataset, labels\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "banner-house",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def train_test(trainModelWeights, testModelWeights, feature='weights', label='one'):\n",
    "    \n",
    "    train_ids = list(range(0, int(trainModelWeights['modelId'].max() + 1)))\n",
    "    test_ids = list(range(0, int(testModelWeights['modelId'].max() + 1)))\n",
    "    train_ids, val_ids = train_test_split(train_ids, test_size = 0.2)\n",
    "    \n",
    "\n",
    "    train_dataset, train_labels = dataset_iterator(train_ids, trainModelWeights, feature, label)\n",
    "    val_dataset, val_labels = dataset_iterator(val_ids, trainModelWeights, feature, label)\n",
    "    test_dataset, test_labels = dataset_iterator(test_ids, testModelWeights, feature, label)\n",
    "    \n",
    "    return np.array(train_dataset), np.array(train_labels), train_ids, \\\n",
    "        np.array(val_dataset), np.array(val_labels), val_ids, \\\n",
    "        np.array(test_dataset),  np.array(test_labels), test_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "25ac4054",
   "metadata": {},
   "outputs": [],
   "source": [
    "# before feature extraction, shape of each layer : \n",
    "# 1 : 1800\n",
    "# 2 : 10368 \n",
    "# 3 : 27648\n",
    "# 4 : 8192\n",
    "# 5 : 1280"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "bc9d54db",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, train_ids, X_val, y_val, val_ids, X_test, y_test, test_ids = train_test(PCA_trainModelWeights, PCA_testModelWeights, feature='pca_weights')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "178fa154",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, y_train, train_ids, X_val, y_val, val_ids, X_test, y_test, test_ids = train_test(trainModelWeights, testModelWeights, feature='weights')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "2c2440a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n# test : \\nfrom torch.nn.utils.rnn import pack_padded_sequence\\n\\n# Could do that, but by considering that the batch size is the number of time-steps \\n# but then i'm not sure that works with the LSTM layer ?\\n\\n# torch.nn.utils.rnn.pack_padded_sequence(input, lengths, batch_first=False, enforce_sorted=True)\\n\\n# input can be of size T x B x * where T is the length of the longest sequence (equal to lengths[0]), \\n# B is the batch size, and * is any number of dimensions (including 0). If batch_first is True, \\n# B x T x * input is expected.\\n\\nlengths = []\\npadded = []\\n\\nfor test in all_test : \\n\\n    test_lengths = [len(layer) for layer in test]\\n    test_max_len = max(test_lengths)\\n    test_padded = [np.pad(layer, (0,test_max_len - len(layer))) for layer in test]\\n\\n    lengths.append(test_lengths)\\n    padded.append(test_padded)\\n\\npadded = torch.Tensor(padded)\\n# input = torch.reshape(padded, (padded.size()[0], padded.size()[2], padded.size()[1]))\\nprint(padded.size())\\nprint(padded[0,:,:].size())\\nprint(torch.Tensor(lengths)[0,:].size())\\npack_padded_sequence(input = padded[0,:,:], lengths = torch.Tensor(lengths)[0,:], batch_first = True, enforce_sorted = False)\\n\\n\""
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "# test : \n",
    "from torch.nn.utils.rnn import pack_padded_sequence\n",
    "\n",
    "# Could do that, but by considering that the batch size is the number of time-steps \n",
    "# but then i'm not sure that works with the LSTM layer ?\n",
    "\n",
    "# torch.nn.utils.rnn.pack_padded_sequence(input, lengths, batch_first=False, enforce_sorted=True)\n",
    "\n",
    "# input can be of size T x B x * where T is the length of the longest sequence (equal to lengths[0]), \n",
    "# B is the batch size, and * is any number of dimensions (including 0). If batch_first is True, \n",
    "# B x T x * input is expected.\n",
    "\n",
    "lengths = []\n",
    "padded = []\n",
    "\n",
    "for test in all_test : \n",
    "\n",
    "    test_lengths = [len(layer) for layer in test]\n",
    "    test_max_len = max(test_lengths)\n",
    "    test_padded = [np.pad(layer, (0,test_max_len - len(layer))) for layer in test]\n",
    "\n",
    "    lengths.append(test_lengths)\n",
    "    padded.append(test_padded)\n",
    "\n",
    "padded = torch.Tensor(padded)\n",
    "# input = torch.reshape(padded, (padded.size()[0], padded.size()[2], padded.size()[1]))\n",
    "print(padded.size())\n",
    "print(padded[0,:,:].size())\n",
    "print(torch.Tensor(lengths)[0,:].size())\n",
    "pack_padded_sequence(input = padded[0,:,:], lengths = torch.Tensor(lengths)[0,:], batch_first = True, enforce_sorted = False)\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "6ca9b0a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((6400, 5, 1000), (6400,), (1600, 5, 1000), (1600,), (2000, 5, 1000), (2000,))"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape, X_val.shape, y_val.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "f0cbeab4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-2.1909920118489135e-05, 8.763968047396391e-05, -5.516476164757478e-19)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(X_train), np.mean(X_val), np.mean(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "a5d4b766",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.14116045827140813, 0.1412076848407677, 0.14806209386862565)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(X_train), np.std(X_val), np.std(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8c94619c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def slicer(batch_size, num_rows, shuffle) :\n",
    "    slices = []\n",
    "\n",
    "    start = 0\n",
    "    end = batch_size\n",
    "    while end <= num_rows :\n",
    "        slices.append((start,end))\n",
    "        start = end\n",
    "        end += batch_size\n",
    "    \n",
    "    if shuffle : \n",
    "        np.random.shuffle(slices)\n",
    "    \n",
    "    return slices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ba9ae8d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "softmax_labels = {0.02 : [1,0,0,0], 0.03 : [0,1,0,0], 0.04 : [0,0,1,0], 0.05 : [0,0,0,1]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6d9506d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# very basic iterator\n",
    "\n",
    "def batcher(X_dataset, y_dataset, batch_size=8, shuffle=True):\n",
    "\n",
    "    num_rows = X_dataset.shape[0]\n",
    "    slices = slicer(batch_size, num_rows, shuffle)\n",
    "\n",
    "    for (start, end) in slices : \n",
    "        batch = torch.Tensor(X_dataset[start:end, :, :])\n",
    "        y_CE = []\n",
    "        for y_label in y_dataset[start:end] : \n",
    "            y_CE.append(softmax_labels[y_label])\n",
    "        #labels = torch.Tensor(y_dataset[start:end])\n",
    "        labels = torch.Tensor(y_CE)\n",
    "        yield (batch, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "fffb50ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# other resources to continue : \n",
    "# https://stackoverflow.com/questions/58251677/how-do-i-train-an-lstm-in-pytorch\n",
    "\n",
    "class Model(nn.Module):\n",
    "    # source : https://pytorch.org/docs/stable/generated/torch.nn.LSTM.html#torch.nn.LSTM \n",
    "    \n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        \n",
    "        # input_size – The number of expected features in the input x\n",
    "        # hidden_size – The number of features in the hidden state h\n",
    "        # num_layers – Number of recurrent layers\n",
    "        # batch_first – If True, then the input and output tensors are provided as (batch, seq, feature)\n",
    "        # bidirectional – If True, becomes a bidirectional LSTM, let's not get too complicated at first\n",
    "        #self.conv1 = nn.Conv1d(27648, 1000, 1)\n",
    "        #self.conv2 = nn.Conv1d(10000, 1000, 1)\n",
    "        #self.conv3 = nn.Conv1d(1000, 100, 1)\n",
    "        self.lstm1 = nn.LSTM(input_size = 1000, hidden_size = 100, num_layers = 1, batch_first = True, bidirectional = False)\n",
    "        self.lstm2 = nn.LSTM(input_size = 100, hidden_size = 10, num_layers = 1, batch_first = True, bidirectional = False)\n",
    "        self.dense = nn.Linear(10, 4)\n",
    "        self.sm = nn.Softmax(dim = 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # input : (N, L, H_in) \n",
    "        # where N = batch size\n",
    "        #       L = sequence length\n",
    "        #       H_in = input size\n",
    "        # -> (batch_size, 5, num_features)\n",
    "        \n",
    "        # some conv1 layer to reduce the number of features\n",
    "\n",
    "        #x = torch.reshape(x, (x.size()[0], x.size()[2], x.size()[1]))\n",
    "        #x = self.conv1(x)\n",
    "        #x = self.conv2(x)\n",
    "        #x = self.conv3(x)\n",
    "        #x = torch.reshape(x, (x.size()[0], x.size()[2], x.size()[1]))\n",
    "        \n",
    "        x, _ = self.lstm1(x)\n",
    "        #print(x.shape)\n",
    "        x, (hidden, cell) = self.lstm2(x)\n",
    "        # hidden : final hidden state for each element in the batch, shape (1, 8, 10) -> reshape into (8,1,10)\n",
    "        hidden = torch.reshape(hidden, shape = (hidden.size()[1], hidden.size()[0], hidden.size()[2]))\n",
    "        #print(x.size())\n",
    "        x = self.dense(hidden)\n",
    "        #print(x.size())\n",
    "        # x = self.sm(x)\n",
    "        #print(x.size())\n",
    "        \n",
    "        return torch.reshape(x, shape = (x.size()[0],x.size()[2]))\n",
    "\n",
    "\n",
    "# input size : (batch_size, 5, num_features) - for the 5 layers, and the features extracted\n",
    "# output size : (batch_size, 1, 1) - for the prediction per model\n",
    "\n",
    "\n",
    "model = Model()\n",
    "# y = model(list(batcher(X_train, y_train))[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "441fc7df",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "categories = {0.02 : 0, 0.03 : 1, 0.04 : 2, 0.05 : 3}\n",
    "\n",
    "def make_categorical(values):\n",
    "    biases = torch.Tensor([0.02, 0.03, 0.04, 0.05])\n",
    "    res = []\n",
    "    for val in values : \n",
    "        idx = torch.argmin(torch.abs(biases - val))\n",
    "        new_val = round(biases[idx].item(), 2)\n",
    "        cat = categories[new_val]\n",
    "        res.append(cat)\n",
    "    return res\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "c218e0fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [04:31<00:00,  5.42s/it]\n"
     ]
    }
   ],
   "source": [
    "from torch import optim\n",
    "from torch.nn import MSELoss, CrossEntropyLoss\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "criterion = CrossEntropyLoss(reduction='mean')\n",
    "optimizer = optim.Adam(model.parameters(), lr = 0.01)\n",
    "\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "NUM_EPOCHS = 50\n",
    "\n",
    "\n",
    "losses = []\n",
    "accuracy = []\n",
    "\n",
    "val_losses = []\n",
    "val_accuracy = []\n",
    "\n",
    "for epoch in tqdm(range(NUM_EPOCHS)):\n",
    "    epoch_loss = []\n",
    "    epoch_accuracies = []\n",
    "\n",
    "    epoch_val_loss = []\n",
    "    epoch_val_accuracies = []\n",
    "\n",
    "    for data in batcher(X_train, y_train, batch_size = BATCH_SIZE) :\n",
    "        \n",
    "        # pass through model\n",
    "        inputs, labels = data\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        \n",
    "        # backprop\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward() \n",
    "        optimizer.step()\n",
    "        epoch_loss.append(loss.item())\n",
    "\n",
    "        # get training accuracy\n",
    "        #cat_preds = make_categorical(outputs)\n",
    "        #cat_labels = make_categorical(labels)\n",
    "        #epoch_accuracies.append(accuracy_score(cat_labels, cat_preds))\n",
    "        y_true = [lab.argmax() for lab in labels]\n",
    "        y_pred = [pred.argmax() for pred in outputs]\n",
    "        epoch_accuracies.append(accuracy_score(y_true, y_pred))\n",
    "\n",
    "    losses.append(np.mean(epoch_loss))\n",
    "    accuracy.append(np.mean(epoch_accuracies))\n",
    "\n",
    "\n",
    "    # Validation accuracies and losses\n",
    "    for data in batcher(X_val, y_val, batch_size=y_val.shape[0]) :\n",
    "        inputs, labels = data\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        # test loss\n",
    "        loss = criterion(outputs, labels)\n",
    "        epoch_val_loss.append(loss.item())\n",
    "\n",
    "        # test accuracy\n",
    "        #cat_preds = make_categorical(outputs)\n",
    "        #cat_labels = make_categorical(labels)\n",
    "        #epoch_val_accuracies.append(accuracy_score(cat_labels, cat_preds))\n",
    "        y_true = [lab.argmax() for lab in labels]\n",
    "        y_pred = [pred.argmax() for pred in outputs]\n",
    "        epoch_val_accuracies.append(accuracy_score(y_true, y_pred))\n",
    "    \n",
    "    val_losses.append(np.mean(epoch_val_loss))\n",
    "    val_accuracy.append(np.mean(epoch_val_accuracies))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "739eb124",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(list(range(len(losses))), losses, label = 'Training')\n",
    "plt.plot(list(range(len(losses))), val_losses, label = 'Validation')\n",
    "plt.title('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.plot(list(range(len(accuracy))), accuracy, label = 'Training')\n",
    "plt.plot(list(range(len(accuracy))), val_accuracy, label = 'Validation')\n",
    "plt.title('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "f9811761",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss :  5.5508646965026855\n",
      "Test accuracy :  0.2455\n"
     ]
    }
   ],
   "source": [
    "# test accuracy : \n",
    "\n",
    "for data in batcher(X_test, y_test, batch_size=y_test.shape[0]) :\n",
    "    inputs, labels = data\n",
    "    outputs = model(inputs)\n",
    "\n",
    "    # test loss\n",
    "    loss = criterion(outputs, labels)\n",
    "\n",
    "    # test accuracy\n",
    "    y_true = [lab.argmax() for lab in labels]\n",
    "    y_pred = [pred.argmax() for pred in outputs]\n",
    "    test_accuracy = accuracy_score(y_true, y_pred)\n",
    "    \n",
    "    #cat_preds = make_categorical(outputs)\n",
    "    #cat_labels = make_categorical(labels)\n",
    "    #accuracy = accuracy_score(cat_labels, cat_preds)\n",
    "\n",
    "print('Test loss : ', loss.item())\n",
    "print('Test accuracy : ', test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb11a1a6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
