{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "departmental-transsexual",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from utils.model_operations import *\n",
    "from utils.image_operations import *\n",
    "\n",
    "directory_path = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "established-taxation",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading model weights with bias 0.02: 100%|██████████| 20/20 [00:05<00:00,  3.96it/s]\n",
      "loading model weights with bias 0.03: 100%|██████████| 20/20 [00:02<00:00,  6.90it/s]\n",
      "loading model weights with bias 0.04: 100%|██████████| 20/20 [00:02<00:00,  6.70it/s]\n",
      "loading model weights with bias 0.05: 100%|██████████| 20/20 [00:02<00:00,  7.65it/s]\n",
      "loading model weights with bias 0.02: 100%|██████████| 5/5 [00:00<00:00,  8.37it/s]\n",
      "loading model weights with bias 0.03: 100%|██████████| 5/5 [00:01<00:00,  4.87it/s]\n",
      "loading model weights with bias 0.04: 100%|██████████| 5/5 [00:01<00:00,  4.68it/s]\n",
      "loading model weights with bias 0.05: 100%|██████████| 5/5 [00:01<00:00,  4.75it/s]\n"
     ]
    }
   ],
   "source": [
    "def loadModelWeights(setName, percentage=1):\n",
    "    \"\"\"\n",
    "    setname: either \"train\" or \"test\"\n",
    "    \n",
    "    returns dataframe with the weights of all models by layers\n",
    "    \"\"\"\n",
    "    bias = ['0.02', '0.03', '0.04', '0.05']\n",
    "    df = pd.DataFrame()\n",
    "    modelId = 0\n",
    "    for b in bias:\n",
    "        if setName == \"train\":\n",
    "            model_data = ModelDataset(bias=b, data_directory=directory_path+'/data/DigitWdb/train')\n",
    "        elif setName == \"test\":\n",
    "            model_data = ModelDataset(bias=b, data_directory=directory_path+'/data/DigitWdb/test')\n",
    "        else:\n",
    "            raise \"set name must either be train or test\"\n",
    "            \n",
    "        for modelNumber in tqdm(range(len(model_data)//percentage), desc=\"loading model weights with bias \"+b):\n",
    "            model = model_data[modelNumber]\n",
    "            layerNumber = 0\n",
    "            for layer in model.layers:\n",
    "                if len(layer.get_weights()) != 0:\n",
    "                    # weights\n",
    "                    weights = layer.get_weights()[0]\n",
    "                    # biases\n",
    "                    biases = layer.get_weights()[1]\n",
    "\n",
    "                    # wandb = np.ravel(weights) + np.ravel(biases)\n",
    "                    \n",
    "                    df = df.append({'modelId':modelId,'weights':np.ravel(weights),'biases':np.ravel(biases),'layer':layerNumber, 'bias':b}, ignore_index=True)\n",
    "                    # df = df.append({'modelId':modelId,'wandb':wandb,'layer':layerNumber, 'bias':b}, ignore_index=True)\n",
    "                    layerNumber = layerNumber + 1\n",
    "            modelId += 1       \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3e11662",
   "metadata": {},
   "outputs": [],
   "source": [
    "int(trainModelWeights['layer'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e437e4fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainModelWeights = loadModelWeights(\"train\")\n",
    "testModelWeights = loadModelWeights(\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "66ef760d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>modelId</th>\n",
       "      <th>weights</th>\n",
       "      <th>biases</th>\n",
       "      <th>layer</th>\n",
       "      <th>bias</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>[-0.018486138, -0.03354981, -0.16535422, -0.06...</td>\n",
       "      <td>[-0.24564764, -0.081536554, -0.01958792, -0.11...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>[-0.26035, -0.031969644, 0.02034611, 0.0241116...</td>\n",
       "      <td>[-0.08751261, 0.14474091, -0.26124775, -0.2221...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>[-0.045246184, -0.022445709, -0.17450637, -0.0...</td>\n",
       "      <td>[0.18726698, -0.055855844, 0.10226409, -0.1979...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>[0.14023237, -0.0014608316, 0.17644557, 0.1682...</td>\n",
       "      <td>[-0.11819455, 0.109577455, -0.034734905, 0.126...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>[-0.25628987, 0.017059373, -0.14892107, 0.1850...</td>\n",
       "      <td>[0.04371279, 0.1927553, -0.0704351, 0.02792670...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>79.0</td>\n",
       "      <td>[0.037538417, -0.084343694, 0.00429407, -0.043...</td>\n",
       "      <td>[-0.011763463, -0.008365027, -0.14752248, -0.1...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>79.0</td>\n",
       "      <td>[0.20852585, -0.23954894, -0.0094635775, -0.06...</td>\n",
       "      <td>[0.06761229, -0.007432909, 0.024540491, -0.137...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>79.0</td>\n",
       "      <td>[0.2562213, 0.039079823, 0.041972984, 0.120924...</td>\n",
       "      <td>[-0.18877326, -0.028655905, -0.026531724, 8.70...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>79.0</td>\n",
       "      <td>[-0.042518232, 0.16675776, 0.5135789, -0.35607...</td>\n",
       "      <td>[-0.12601914, 0.22279127, 0.93562245, 0.575864...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>79.0</td>\n",
       "      <td>[0.026178522, 0.14872243, 0.12535143, -0.00353...</td>\n",
       "      <td>[-0.02915595, 0.12834957, 0.07938649, 0.122114...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     modelId                                            weights  \\\n",
       "0        0.0  [-0.018486138, -0.03354981, -0.16535422, -0.06...   \n",
       "1        0.0  [-0.26035, -0.031969644, 0.02034611, 0.0241116...   \n",
       "2        0.0  [-0.045246184, -0.022445709, -0.17450637, -0.0...   \n",
       "3        0.0  [0.14023237, -0.0014608316, 0.17644557, 0.1682...   \n",
       "4        0.0  [-0.25628987, 0.017059373, -0.14892107, 0.1850...   \n",
       "..       ...                                                ...   \n",
       "395     79.0  [0.037538417, -0.084343694, 0.00429407, -0.043...   \n",
       "396     79.0  [0.20852585, -0.23954894, -0.0094635775, -0.06...   \n",
       "397     79.0  [0.2562213, 0.039079823, 0.041972984, 0.120924...   \n",
       "398     79.0  [-0.042518232, 0.16675776, 0.5135789, -0.35607...   \n",
       "399     79.0  [0.026178522, 0.14872243, 0.12535143, -0.00353...   \n",
       "\n",
       "                                                biases  layer  bias  \n",
       "0    [-0.24564764, -0.081536554, -0.01958792, -0.11...    0.0  0.02  \n",
       "1    [-0.08751261, 0.14474091, -0.26124775, -0.2221...    1.0  0.02  \n",
       "2    [0.18726698, -0.055855844, 0.10226409, -0.1979...    2.0  0.02  \n",
       "3    [-0.11819455, 0.109577455, -0.034734905, 0.126...    3.0  0.02  \n",
       "4    [0.04371279, 0.1927553, -0.0704351, 0.02792670...    4.0  0.02  \n",
       "..                                                 ...    ...   ...  \n",
       "395  [-0.011763463, -0.008365027, -0.14752248, -0.1...    0.0  0.05  \n",
       "396  [0.06761229, -0.007432909, 0.024540491, -0.137...    1.0  0.05  \n",
       "397  [-0.18877326, -0.028655905, -0.026531724, 8.70...    2.0  0.05  \n",
       "398  [-0.12601914, 0.22279127, 0.93562245, 0.575864...    3.0  0.05  \n",
       "399  [-0.02915595, 0.12834957, 0.07938649, 0.122114...    4.0  0.05  \n",
       "\n",
       "[400 rows x 5 columns]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainModelWeights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "65ac001a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1280,)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = trainModelWeights[trainModelWeights['modelId'] == 0][[feature]].values[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cab6be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterate_over_ids(modelid, trainModelWeights, testModelWeights = None, test = False):\n",
    "\n",
    "    if testModelWeights is not None : \n",
    "\n",
    "\n",
    "    X_train = trainModelWeights[trainModelWeights['modelId'] == modelid][[feature]].values[:,0]\n",
    "    y_train = trainModelWeights[trainModelWeights['modelId'] == modelid][['bias']].values[:,0][0]\n",
    "\n",
    "    layers = []\n",
    "    for i, layer in enumerate(X_train) : \n",
    "        # For now, randomly reduce dimension\n",
    "        # TO DO : CNN feature reduction \n",
    "        layer = np.random.choice(layer, size=100, replace=False) \n",
    "        layers.append(layer)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "banner-house",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "def train_test(trainModelWeights, testModelWeights = None, feature='weights'):\n",
    "\n",
    "    train_dataset = []\n",
    "    test_dataset = []\n",
    "    \n",
    "    train_ids = list(range(0, int(trainModelWeights['modelId'].max() + 1)))\n",
    "    if testModelWeights is not None : \n",
    "        test_ids = list(range(0, int(testModelWeights['modelId'].max() + 1)))\n",
    "    else : \n",
    "        train_ids, test_ids = train_test_split(train_ids, test_size=0.2)\n",
    "    \n",
    "\n",
    "    for modelid in train_ids :\n",
    "\n",
    "        X_train = trainModelWeights[trainModelWeights['modelId'] == modelid][[feature]].values[:,0]\n",
    "        y_train = trainModelWeights[trainModelWeights['modelId'] == modelid][['bias']].values[:,0][0]\n",
    "\n",
    "        layers = []\n",
    "        for i, layer in enumerate(X_train) : \n",
    "            # TO DO : CNN feature reduction \n",
    "            layer = np.random.choice(layer, size=100, replace=False) \n",
    "            layers.append(layer)\n",
    "        train_dataset.append(layers)\n",
    "\n",
    "    for modelid in test_ids : \n",
    "\n",
    "        if testModelWeights is not None : \n",
    "            X_test = testModelWeights[testModelWeights['modelId'] == modelid][[feature]].values[:,0]\n",
    "            y_test = testModelWeights[testModelWeights['modelId'] == modelid][['bias']].values[:,0][0]\n",
    "        else : \n",
    "            X_test = trainModelWeights[trainModelWeights['modelId'] == modelid][[feature]].values[:,0]\n",
    "            y_test = trainModelWeights[trainModelWeights['modelId'] == modelid][['bias']].values[:,0][0]\n",
    "        \n",
    "        layers = []\n",
    "        for i, layer in enumerate(X_train) : \n",
    "            # TO DO : CNN feature reduction \n",
    "            layer = np.random.choice(layer, size=100, replace=False) \n",
    "            layers.append(layer)\n",
    "        test_dataset.append(layers)\n",
    "\n",
    "\n",
    "    # most important : dataset\n",
    "    return np.array(train_dataset), np.array(test_dataset), train_ids, test_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "178fa154",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, test_dataset, train_ids, test_ids = train_test(trainModelWeights, feature='weights')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "eef6e8d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((64, 5, 100), (16, 5, 100))"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.shape, test_dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "6d9506d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# very basic iterator\n",
    "\n",
    "def batcher(dataset, batch_size=8):\n",
    "\n",
    "    num_rows = dataset.shape[0]\n",
    "\n",
    "    start = 0\n",
    "    end = batch_size\n",
    "    while end <= num_rows : \n",
    "        batch = dataset[start:end, :, :]\n",
    "        yield batch\n",
    "        start = end\n",
    "        end += batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "4ff3ed49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 5, 100)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# batch\n",
    "batch = np.array(train_dataset)[:8,:,:]\n",
    "batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "83f6a9db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 5, 100])"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.Tensor(batch).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "fffb50ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# other resources to continue : \n",
    "# https://stackoverflow.com/questions/58251677/how-do-i-train-an-lstm-in-pytorch\n",
    "\n",
    "class Model(nn.Module):\n",
    "    # source : https://pytorch.org/docs/stable/generated/torch.nn.LSTM.html#torch.nn.LSTM \n",
    "    # * = to be experimented with\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        \n",
    "        # input_size – The number of expected features in the input x\n",
    "        # hidden_size – The number of features in the hidden state h\n",
    "        # num_layers – Number of recurrent layers\n",
    "        # batch_first – If True, then the input and output tensors are provided as (batch, seq, feature)\n",
    "        # bidirectional – If True, becomes a bidirectional LSTM, let's not get too complicated at first\n",
    "        self.lstm = nn.LSTM(input_size = 100, hidden_size = 10, num_layers = 1, batch_first = True, bidirectional = False)\n",
    "        self.dense = nn.Linear(10, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # input : (N, L, H_in) \n",
    "        # where N = batch size\n",
    "        #       L = sequence length\n",
    "        #       H_in = input size\n",
    "        # -> (batch_size, 5, num_features)\n",
    "\n",
    "        # Note : The input can also be a packed variable length sequence\n",
    "        \n",
    "        x, _ = self.lstm(x)\n",
    "        x = self.dense(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "model = Model()\n",
    "# batch size : (8, 5, 100)\n",
    "y = model(torch.Tensor(batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "b87cd5fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0469],\n",
       "        [-0.0699],\n",
       "        [-0.0493],\n",
       "        [-0.1235],\n",
       "        [-0.0808]], grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c218e0fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.RMSprop(model.parameters()) \n",
    "\n",
    "for epoch in range(25):\n",
    "    acc_loss = 0.\n",
    "    acc_mae = 0.   \n",
    "\n",
    "    # define dataset to be loadable by batches\n",
    "    for data in batcher(train_dataset, batch_size=8) :\n",
    "        inputs, labels = data\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward(retain_graph = True)\n",
    "        optimizer.step()\n",
    "        acc_loss += loss.item()\n",
    "        mae = mean_absolute_error(labels.detach().cpu().numpy().flatten(), outputs.detach().cpu().numpy().flatten())\n",
    "        acc_mae += mae"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
